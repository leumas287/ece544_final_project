{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "#Overlay(\"base.bit\").download()\n",
    "# initialize camera from OpenCV\n",
    "from pynq.drivers import Frame\n",
    "import cv2\n",
    "import math\n",
    "# Output webcam image as JPEG\n",
    "%pylab inline \n",
    "from IPython.display import clear_output\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# monitor configuration: 640*480 @ 60Hz\n",
    "from pynq.drivers import HDMI\n",
    "from pynq.drivers.video import VMODE_640x480\n",
    "hdmi_out = HDMI('out', video_mode=VMODE_640x480)\n",
    "hdmi_out.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pynq.iop import Robot_Controller\n",
    "my_robot = Robot_Controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# monitor (output) frame buffer size\n",
    "frame_out_w = 1920\n",
    "frame_out_h = 1080\n",
    "# camera (input) configuration\n",
    "frame_in_w = 320 #640\n",
    "frame_in_h = 240 #480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_shape(contours):\n",
    "    approx = cv2.approxPolyDP(contours,0.01*cv2.arcLength(contours,True),True) \n",
    "    if len(approx) == 4:\n",
    "        return \"square\"\n",
    "            \n",
    "    elif len(approx) > 8 and len(approx) < 12:\n",
    "        return \"cylinder\"        \n",
    "    else:\n",
    "        return \"invalid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_box_points(contours):\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.array(box, dtype=\"int\")\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    \n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    \n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_dimensions(pts,known_width):\n",
    "    dimensions = {\"height_px\":None, \"width_px\":None, \"w_In\":None}\n",
    "    \n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    # compute the width of the bounding box, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    dimensions[\"width_px\"] = maxWidth\n",
    "    dimensions[\"w_In\"] = maxWidth/known_width\n",
    "              \n",
    "    # compute the height of the bounding box, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dimensions[\"height_px\"] = maxHeight\n",
    "    return dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_frame_pos(centerX):\n",
    "    position = ''\n",
    "    \n",
    "    if (int(centerX) > 0) and (int(centerX) < 213):\n",
    "        position = \"left\"  \n",
    "    \n",
    "    elif (int(centerX) > 213) and (int(centerX) < 426):\n",
    "        position = \"middle\"\n",
    "     \n",
    "    else:    \n",
    "        position =\"right\"   \n",
    "    \n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_object_x_offset(centerX):\n",
    "    # Find the x offset by taking the frame center (width/2) and subtract the current object's x-center.\n",
    "    # This means that an object to the left of center will have a positive value and an object to the right\n",
    "    # of center will have a negative value.  The offset should be at most abs(frame_in_w/2)\n",
    "    return (frame_in_w/2) - centerX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def distance_to_camera(knownWidth, focalLength, percieved_width):\n",
    "    # compute and return the distance from the maker to the camera\n",
    "    return (knownWidth * focalLength) / percieved_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_distance(known_width,focalLength, perWidth):\n",
    "    inches = distance_to_camera(known_width, focalLength, perWidth)\n",
    "    return inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def center_to_object(xOffset):\n",
    "    absX = abs(xOffset)\n",
    "    if absX > 20:\n",
    "        if xOffset < 0:\n",
    "            my_robot.left()\n",
    "            print(xOffset)\n",
    "        else:\n",
    "            my_robot.right()\n",
    "            print(xOffset)\n",
    "    elif absX <= 20:\n",
    "        centered = True\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def approach_object(distance):\n",
    "    my_robot.release()\n",
    "    for i in range(0,math.floor(distance)):\n",
    "        my_robot.forward(0.05)\n",
    "    \n",
    "    my_robot.grip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_can(position, distance):\n",
    "    if not centered:\n",
    "        center_to_object(position)\n",
    "    else:\n",
    "        approach_object(distance)\n",
    "        \n",
    "                \n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Camera Calibration\n",
    "#Known width/height of coke can\n",
    "KNOWN_CAN_WIDTH          = 2.598  # inches\n",
    "KNOWN_TARGET_WIDTH       = 13.937 # inches\n",
    "KNOWN_CAN_PIXEL_WIDTH    = 133\n",
    "KNOWN_TARGET_PIXEL_WIDTH = 344\n",
    "KNOWN_CAN_DISTANCE       = 12 #empirically derived distance from lens to coke can\n",
    "KNOWN_TARGET_DISTANCE    = 26 # inches\n",
    "focalLength_can = (KNOWN_CAN_PIXEL_WIDTH * KNOWN_CAN_DISTANCE) / KNOWN_CAN_WIDTH\n",
    "focalLength_target = (KNOWN_TARGET_PIXEL_WIDTH * KNOWN_TARGET_DISTANCE) / KNOWN_TARGET_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0)\n",
    "shape =' '\n",
    "results ={}\n",
    "position=' '\n",
    "distance = 0\n",
    "cnt_length = 0\n",
    "centered = False\n",
    "\n",
    "# define range of red color in HSV\n",
    "lower_red = np.array([17, 15, 100], dtype=np.uint8)\n",
    "upper_red = np.array([50, 56, 200], dtype=np.uint8)\n",
    "# define range of green color in HSV\n",
    "lower_green = np.array([34, 50, 50], dtype=np.uint8)\n",
    "upper_green = np.array([80, 220, 200], dtype=np.uint8)\n",
    "# define range of blue color in HSV\n",
    "lower_blue = np.array([92, 0, 0], dtype=np.uint8)\n",
    "upper_blue = np.array([124, 255, 255], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture device is open: True\n"
     ]
    }
   ],
   "source": [
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h);\n",
    "\n",
    "print(\"Capture device is open: \" + str(videoIn.isOpened()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "try:\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = videoIn.read()\n",
    "        if not ret:\n",
    "            # Release the Video Device if ret is false\n",
    "            videoIn.release()\n",
    "            # Message to be displayed after releasing the device\n",
    "            print (\"Released Video Resource\")\n",
    "            break \n",
    "            \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        hsv =  hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        # Turn off the axis\n",
    "        axis('off')\n",
    "        \n",
    "        # Threshold the HSV image to get only red colors\n",
    "        mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        mask_green = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        mask_blue  = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "        mask_zero = np.zeros(hsv.shape[:2],np.uint8)\n",
    "        \n",
    "        # RGB to Gray scale conversion\n",
    "        img_gray = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)\n",
    "        # Noise removal with iterative bilateral filter(removes noise while preserving edges)\n",
    "        noise_removal = cv2.bilateralFilter(img_gray,9,75,75)\n",
    "        # Thresholding the image\n",
    "        ret,thresh_image = cv2.threshold(noise_removal,0,255,cv2.THRESH_OTSU)\n",
    "    \n",
    "        # Applying Canny Edge detection\n",
    "        canny_image = cv2.Canny(thresh_image,250,255)\n",
    "        # Display Image\n",
    "        canny_image = cv2.convertScaleAbs(canny_image)\n",
    "    \n",
    "        # dilation to strengthen the edges\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        # Creating the kernel for dilation\n",
    "        dilated_image = cv2.dilate(canny_image,kernel,iterations=1)\n",
    "    \n",
    "        #find contour data\n",
    "        __,contours,__ = cv2.findContours(dilated_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        contours= sorted(contours, key = cv2.contourArea, reverse = True)[:1]\n",
    "        for cnt in contours:\n",
    "        # if the contour is not sufficiently large, ignore it\n",
    "            if cv2.contourArea(cnt) < 100:\n",
    "                continue\n",
    "            shape = update_shape(cnt)\n",
    "            if (shape == \"square\"):\n",
    "                rect = cv2.minAreaRect(cnt)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.array(box, dtype=\"int\")\n",
    "                cX = np.average(box[:, 0])\n",
    "                # compute the center of the bounding box\n",
    "                cX = np.average(box[:, 0])\n",
    "                results = get_dimensions(box, KNOWN_TARGET_WIDTH)\n",
    "                position = find_object_x_offset(cX)\n",
    "                center_to_object(position)\n",
    "                distance = update_distance(KNOWN_TARGET_WIDTH, focalLength_can, results[\"width_px\"]) \n",
    "                approach_object(distance)\n",
    "                print(results)\n",
    "                print(position)\n",
    "                print(\"dist from camera:\", distance)\n",
    "                if cv2.countNonZero(mask_blue):\n",
    "                    print(\"Blue detected\")\n",
    "                    mask_green = mask_zero\n",
    "                    mask_red = mask_zero\n",
    "                    cv2.drawContours(frame,[box],0,(0,0,255),2)\n",
    "                else:\n",
    "                    continue\n",
    "            elif (shape == \"cylinder\"):\n",
    "                rect = cv2.minAreaRect(cnt)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.array(box, dtype=\"int\")\n",
    "                cX = np.average(box[:, 0])\n",
    "                # compute the center of the bounding box\n",
    "                cX = np.average(box[:, 0])\n",
    "                results = get_dimensions(box, KNOWN_CAN_WIDTH)\n",
    "                position = find_frame_pos(cX)\n",
    "                distance = update_distance(KNOWN_CAN_WIDTH, focalLength_can, results[\"width_px\"]) \n",
    "                print(results)\n",
    "                print(position)\n",
    "                print(\"dist from camera:\", distance)\n",
    "                if cv2.countNonZero(mask_red):\n",
    "                    print(\"Red detected\")\n",
    "                    mask_green = mask_zero\n",
    "                    mask_blue = mask_zero\n",
    "                    cv2.drawContours(frame,[box],0,(0,0,255),2)\n",
    "                else:\n",
    "                    continue\n",
    "        imshow(frame)\n",
    "        show()\n",
    "        # Display the frame until new frame is available\n",
    "        clear_output(wait=True)\n",
    "#         break\n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    print(\"Released Video Resource\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = videoIn.read()\n",
    "    if not ret:\n",
    "        # Release the Video Device if ret is false\n",
    "        videoIn.release()\n",
    "        # Message to be displayed after releasing the device\n",
    "        print (\"Released Video Resource\")\n",
    "        break   \n",
    "    # Our operations on the frame come here\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Turn off the axis\n",
    "    axis('off')\n",
    "    # Threshold the HSV image to get only red colors\n",
    "    mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    mask_green = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    mask_blue  = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    mask_zero = np.zeros(hsv.shape[:2],np.uint8)\n",
    "    \n",
    "    # RGB to Gray scale conversion\n",
    "    img_gray = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)\n",
    "    # Noise removal with iterative bilateral filter(removes noise while preserving edges)\n",
    "    noise_removal = cv2.bilateralFilter(img_gray,9,75,75)\n",
    "    # Thresholding the image\n",
    "    ret,thresh_image = cv2.threshold(noise_removal,0,255,cv2.THRESH_OTSU)\n",
    "\n",
    "    # Applying Canny Edge detection\n",
    "    canny_image = cv2.Canny(thresh_image,250,255)\n",
    "    # Display Image\n",
    "    canny_image = cv2.convertScaleAbs(canny_image)\n",
    "\n",
    "    # dilation to strengthen the edges\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    # Creating the kernel for dilation\n",
    "    dilated_image = cv2.dilate(canny_image,kernel,iterations=1)\n",
    "   \n",
    "    \n",
    "    #find contour data\n",
    "    __,contours,__ = cv2.findContours(dilated_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours= sorted(contours, key = cv2.contourArea, reverse = True)[:1]\n",
    "    pt = (180, 3 * frame.shape[0] // 4)\n",
    "    for cnt in contours:\n",
    "        # if the contour is not sufficiently large, ignore it\n",
    "        if cv2.contourArea(cnt) < 100:\n",
    "            continue\n",
    "            \n",
    "        shape = update_shape(cnt)\n",
    "        if (shape == \"square\"):\n",
    "            rect = cv2.minAreaRect(cnt)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.array(box, dtype=\"int\")\n",
    "            cX = np.average(box[:, 0])\n",
    "            # compute the center of the bounding box\n",
    "            cX = np.average(box[:, 0])\n",
    "            results = get_dimensions(box, KNOWN_TARGET_WIDTH)\n",
    "            position = find_object_x_offset(cX)\n",
    "            center_to_object(position)\n",
    "            distance = update_distance(KNOWN_TARGET_WIDTH, focalLength_can, results[\"width_px\"]) \n",
    "            approach_object(distance)\n",
    "            print(results)\n",
    "            print(position)\n",
    "            print(\"dist from camera:\", distance)\n",
    "            if cv2.countNonZero(mask_blue):\n",
    "                print(\"Blue detected\")\n",
    "                mask_green = mask_zero\n",
    "                mask_red = mask_zero\n",
    "                cv2.drawContours(frame,[box],0,(0,0,255),2)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        elif (shape == \"cylinder\"):\n",
    "            rect = cv2.minAreaRect(cnt)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.array(box, dtype=\"int\")\n",
    "            cX = np.average(box[:, 0])\n",
    "            # compute the center of the bounding box\n",
    "            cX = np.average(box[:, 0])\n",
    "            results = get_dimensions(box, KNOWN_CAN_WIDTH)\n",
    "            position = find_object_x_offset(cX)\n",
    "            distance = update_distance(KNOWN_CAN_WIDTH, focalLength_can, results[\"width_px\"])\n",
    "            break\n",
    "            \n",
    "            '''\n",
    "            if not centered:\n",
    "                center_to_object(position)\n",
    "            else:\n",
    "                approach_object(distance)\n",
    "                break\n",
    "            '''\n",
    "        # get_can(position,distance)  \n",
    "        print(results)\n",
    "        print(position)\n",
    "        print(\"dist from camera:\", distance)\n",
    "        if cv2.countNonZero(mask_red):\n",
    "            print(\"Red detected\")\n",
    "            mask_green = mask_zero\n",
    "            mask_blue = mask_zero\n",
    "            cv2.drawContours(frame,[box],0,(0,0,255),2)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Capture webcam image\n",
    "import numpy as np\n",
    "\n",
    "ret, frame_vga = videoIn.read()\n",
    "\n",
    "# Display webcam image via HDMI Out\n",
    "if (ret):\n",
    "    frame_1080p = np.zeros((1080,1920,3)).astype(np.uint8)       \n",
    "    frame_1080p[0:480,0:640,:] = frame_vga[0:480,0:640,:]\n",
    "    hdmi_out.frame_raw(bytearray(frame_1080p.astype(np.int8).tobytes()))\n",
    "else:\n",
    "    raise RuntimeError(\"Failed to read from camera.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Output webcam image as JPEG\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(frame_vga[:,:,[2,1,0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "np_frame = frame_vga\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "                        './data/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(\n",
    "                        './data/haarcascade_eye.xml')\n",
    "\n",
    "gray = cv2.cvtColor(np_frame, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(np_frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = np_frame[y:y+h, x:x+w]\n",
    "\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Output OpenCV results via HDMI\n",
    "frame_1080p[0:480,0:640,:] = frame_vga[0:480,0:640,:]\n",
    "hdmi_out.frame_raw(bytearray(frame_1080p.astype(np.int8).tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Output OpenCV results via matplotlib\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(np_frame[:,:,[2,1,0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "videoIn.release()\n",
    "hdmi_out.stop()\n",
    "del hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
